{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-07-22T11:45:47.807934Z","iopub.status.busy":"2024-07-22T11:45:47.807582Z","iopub.status.idle":"2024-07-22T11:45:51.247882Z","shell.execute_reply":"2024-07-22T11:45:51.247110Z","shell.execute_reply.started":"2024-07-22T11:45:47.807910Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/var/folders/v9/wq9d9w3501v5y6219s4smvyw0000gn/T/ipykernel_34865/2445178329.py:1: DeprecationWarning: \n","Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n","(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n","but was not found to be installed on your system.\n","If this would cause problems for you,\n","please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n","        \n","  import pandas as pd\n"]}],"source":["import pandas as pd\n","import torch\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import torch\n","import random\n"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-07-22T11:45:51.249940Z","iopub.status.busy":"2024-07-22T11:45:51.249543Z","iopub.status.idle":"2024-07-22T11:45:51.258088Z","shell.execute_reply":"2024-07-22T11:45:51.257236Z","shell.execute_reply.started":"2024-07-22T11:45:51.249913Z"},"trusted":true},"outputs":[],"source":["#set seed for everything\n","torch.manual_seed(0)\n","np.random.seed(0)\n","random.seed(0)"]},{"cell_type":"markdown","metadata":{},"source":["#训练方案分析\n","原模型是在sn>1的样本上进行finetune训练的。\n","\n","但是对于sn较差的样本没有理会，\n","- 应该在这些样本上进行semi-supervise。\n","- 最后在真实样本上再进行退火处理。"]},{"cell_type":"markdown","metadata":{},"source":["# Get data and do some data processing"]},{"cell_type":"markdown","metadata":{},"source":["# Get pytorch dataset"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-07-22T11:46:24.910584Z","iopub.status.busy":"2024-07-22T11:46:24.910106Z","iopub.status.idle":"2024-07-22T11:46:24.921278Z","shell.execute_reply":"2024-07-22T11:46:24.920335Z","shell.execute_reply.started":"2024-07-22T11:46:24.910552Z"},"trusted":true},"outputs":[],"source":["from torch.utils.data import Dataset, DataLoader\n","from ast import literal_eval\n","\n","\n","from Network import *\n","import yaml\n","\n","\n","\n","class Config:\n","    def __init__(self, **entries):\n","        self.__dict__.update(entries)\n","        self.entries=entries\n","\n","    def print(self):\n","        print(self.entries)\n","\n","def load_config_from_yaml(file_path):\n","    with open(file_path, 'r') as file:\n","        config = yaml.safe_load(file)\n","    return Config(**config)\n","\n","class finetuned_RibonanzaNet(RibonanzaNet):\n","    def __init__(self, config, pretrained=False):\n","        super(finetuned_RibonanzaNet, self).__init__(config)\n","        if pretrained:\n","            self.load_state_dict(torch.load(\"/kaggle/input/ribonanzanet-weights/RibonanzaNet.pt\",map_location='cpu'))\n","        self.decoder=nn.Linear(256,5)\n","\n","    def forward(self,src):\n","        \n","        sequence_features, pairwise_features=self.get_embeddings(src, torch.ones_like(src).long().to(src.device))\n","        output=self.decoder(sequence_features)\n","\n","        return output.squeeze(-1)\n","    \n","\n","class RNA_test_Dataset(Dataset):\n","    def __init__(self,data):\n","        self.data=data\n","        self.tokens={nt:i for i,nt in enumerate('ACGU')}\n","\n","    def __len__(self):\n","        return len(self.data)\n","    \n","    def __getitem__(self, idx):\n","        sequence=[self.tokens[nt] for nt in self.data.loc[idx,'sequence']]\n","        sequence=np.array(sequence)\n","        sequence=torch.tensor(sequence)\n","\n","        return {'sequence':sequence}\n","\n","class RNA_Dataset(Dataset):\n","    def __init__(self,data, length=68):\n","        self.data=data\n","        self.length=length\n","        self.tokens={nt:i for i,nt in enumerate('ACGU')}\n","        self.label_names=['reactivity', 'deg_Mg_pH10', 'deg_pH10', 'deg_Mg_50C', 'deg_50C']\n","               \n","    def __len__(self):\n","        return len(self.data)\n","    \n","    def __getitem__(self, idx):\n","        sequence=[self.tokens[nt] for nt in (self.data.loc[idx,'sequence'])]\n","        sequence=np.array(sequence)\n","        sequence=torch.tensor(sequence)\n","        if len(sequence)<self.length:\n","            sequence=torch.cat([sequence,torch.ones(self.length-len(sequence)).long()*4])\n","        labels=np.stack([self.data.loc[idx,l] for l in self.label_names],-1)\n","        labels=torch.tensor(labels)\n","        if len(labels)>self.length:\n","            labels=labels[:self.length]\n","        else:\n","            labels=torch.cat([labels,torch.zeros(self.length-len(labels),5)])\n","        return {'sequence':sequence,\n","                'labels':labels}"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["constructing 9 ConvTransformerEncoderLayers\n"]},{"data":{"text/plain":["<All keys matched successfully>"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["config=load_config_from_yaml(\"/Users/lihongmin/Research/ideas/RibonanzaNet/ribonanzanet2d-final/configs/pairwise.yaml\")\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","if torch.backends.mps.is_available():\n","    device= torch.device(\"mps\")\n","model=finetuned_RibonanzaNet(config,pretrained=False).to(device)\n","#1. Initial Model Training-only confident labels:\n","model.load_state_dict(torch.load(\"/Users/lihongmin/Research/ideas/RibonanzaNet/ribonanzanet-weights/RibonanzaNet-Deg21.pt\",map_location=device))"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-07-22T11:46:26.065820Z","iopub.status.busy":"2024-07-22T11:46:26.065433Z","iopub.status.idle":"2024-07-22T11:46:26.336736Z","shell.execute_reply":"2024-07-22T11:46:26.335553Z","shell.execute_reply.started":"2024-07-22T11:46:26.065794Z"},"trusted":true},"outputs":[],"source":["data=pd.read_json(\"train_pseudo.json\",lines=True).reset_index(drop=True)\n","data_noisy = data.loc[data['signal_to_noise']<=1].reset_index(drop=True)\n","data=data.loc[data['signal_to_noise']>1].reset_index(drop=True)\n","test107 = pd.read_json(\"test_pseudo_107.json\",lines=True).reset_index(drop=True)\n","test130 = pd.read_json(\"test_pseudo_130.json\",lines=True).reset_index(drop=True)"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"data":{"text/plain":["Text(0.5, 0, 'signal_to_noise')"]},"execution_count":6,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["from sklearn.model_selection import KFold, StratifiedKFold\n","data['length']=data['sequence'].apply(len)\n","kf = StratifiedKFold(n_splits=10,random_state=2020, shuffle=True)\n","for i, (train_index, val_index) in enumerate(kf.split(data,data['SN_filter'])):\n","    break\n","\n","train_split=data.loc[train_index].reset_index(drop=True)\n","val_split=data.loc[val_index].reset_index(drop=True)\n","val_split=val_split.loc[val_split['signal_to_noise']>1].reset_index(drop=True)\n","\n","plt.hist(train_split['signal_to_noise'],bins=30)\n","plt.hist(val_split['signal_to_noise'],bins=30)\n","plt.xlabel('signal_to_noise')"]},{"cell_type":"markdown","metadata":{},"source":["# copy pseudo label for noisy data"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"data":{"text/plain":["Index(['index', 'id', 'sequence', 'structure', 'predicted_loop_type',\n","       'signal_to_noise', 'SN_filter', 'seq_length', 'seq_scored',\n","       'reactivity_error', 'deg_error_Mg_pH10', 'deg_error_pH10',\n","       'deg_error_Mg_50C', 'deg_error_50C', 'reactivity', 'deg_Mg_pH10',\n","       'deg_pH10', 'deg_Mg_50C', 'deg_50C', 'pseudo_reactivity',\n","       'pseudo_deg_Mg_pH10', 'pseudo_deg_pH10', 'pseudo_deg_Mg_50C',\n","       'pseudo_deg_50C'],\n","      dtype='object')"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["data_noisy.columns"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["data_noisy[['reactivity', 'deg_Mg_pH10',\n","       'deg_pH10', 'deg_Mg_50C', 'deg_50C']] = data_noisy[['pseudo_reactivity',\n","       'pseudo_deg_Mg_pH10', 'pseudo_deg_pH10', 'pseudo_deg_Mg_50C',\n","       'pseudo_deg_50C']]\n","\n","test107[['reactivity', 'deg_Mg_pH10',\n","       'deg_pH10', 'deg_Mg_50C', 'deg_50C']] = test107[['pseudo_reactivity',\n","       'pseudo_deg_Mg_pH10', 'pseudo_deg_pH10', 'pseudo_deg_Mg_50C',\n","       'pseudo_deg_50C']]\n","test130[['reactivity', 'deg_Mg_pH10',\n","       'deg_pH10', 'deg_Mg_50C', 'deg_50C']] = test130[['pseudo_reactivity',\n","       'pseudo_deg_Mg_pH10', 'pseudo_deg_pH10', 'pseudo_deg_Mg_50C',\n","       'pseudo_deg_50C']]\n","\n","# 将train_split的前68个值保留原样，后面的值用pseudo的值替代\n","# train_step3=pd.concat([train_split,data_noisy,test107,test130],axis=0).reset_index(drop=True)\n","# train_step3\n","train_split['reactivity'] = train_split.apply(lambda x: x['reactivity'] + x['pseudo_reactivity'][68:], axis=1)\n","train_split['deg_Mg_pH10'] = train_split.apply(lambda x: x['deg_Mg_pH10'] + x['pseudo_deg_Mg_pH10'][68:], axis=1)\n","train_split['deg_pH10'] = train_split.apply(lambda x: x['deg_pH10'] + x['pseudo_deg_pH10'][68:], axis=1)\n","train_split['deg_Mg_50C'] = train_split.apply(lambda x: x['deg_Mg_50C'] + x['pseudo_deg_Mg_50C'][68:], axis=1)\n","train_split['deg_50C'] = train_split.apply(lambda x: x['deg_50C'] + x['pseudo_deg_50C'][68:], axis=1)\n","train_step3=pd.concat([train_split,data_noisy,test107,test130],axis=0).reset_index(drop=True)\n"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>index</th>\n","      <th>id</th>\n","      <th>sequence</th>\n","      <th>structure</th>\n","      <th>predicted_loop_type</th>\n","      <th>signal_to_noise</th>\n","      <th>SN_filter</th>\n","      <th>seq_length</th>\n","      <th>seq_scored</th>\n","      <th>reactivity_error</th>\n","      <th>...</th>\n","      <th>deg_Mg_pH10</th>\n","      <th>deg_pH10</th>\n","      <th>deg_Mg_50C</th>\n","      <th>deg_50C</th>\n","      <th>pseudo_reactivity</th>\n","      <th>pseudo_deg_Mg_pH10</th>\n","      <th>pseudo_deg_pH10</th>\n","      <th>pseudo_deg_Mg_50C</th>\n","      <th>pseudo_deg_50C</th>\n","      <th>length</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>id_001f94081</td>\n","      <td>GGAAAAGCUCUAAUAACAGGAGACUAGGACUACGUAUUUCUAGGUA...</td>\n","      <td>.....((((((.......)))).)).((.....((..((((((......</td>\n","      <td>EEEEESSSSSSHHHHHHHSSSSBSSXSSIIIIISSIISSSSSSHHH...</td>\n","      <td>6.894</td>\n","      <td>1.0</td>\n","      <td>107</td>\n","      <td>68</td>\n","      <td>[0.1359, 0.20700000000000002, 0.1633, 0.1452, ...</td>\n","      <td>...</td>\n","      <td>[0.7556, 2.983, 0.2526, 1.3789, 0.637600000000...</td>\n","      <td>[2.3375, 3.5060000000000002, 0.3008, 1.0108, 0...</td>\n","      <td>[0.35810000000000003, 2.9683, 0.2589, 1.4552, ...</td>\n","      <td>[0.6382, 3.4773, 0.9988, 1.3228, 0.78770000000...</td>\n","      <td>[0.34715089200000004, 1.5796933174, 1.12351059...</td>\n","      <td>[0.6049603224, 2.9363353252, 0.2550430596, 1.2...</td>\n","      <td>[2.6121025085, 3.5633585453, 0.3173390031, 0.9...</td>\n","      <td>[0.4698945284, 3.3145470619, 0.2526535988, 1.6...</td>\n","      <td>[0.7628977299, 3.3258330822, 0.772382319000000...</td>\n","      <td>107.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>id_006f36f57</td>\n","      <td>GGAAAGUGCUCAGAUAAGCUAAGCUCGAAUAGCAAUCGAAUAGAAU...</td>\n","      <td>.....((((.((.....((((.(((.....)))..((((......)...</td>\n","      <td>EEEEESSSSISSIIIIISSSSMSSSHHHHHSSSMMSSSSHHHHHHS...</td>\n","      <td>8.800</td>\n","      <td>1.0</td>\n","      <td>107</td>\n","      <td>68</td>\n","      <td>[0.0931, 0.13290000000000002, 0.11280000000000...</td>\n","      <td>...</td>\n","      <td>[0.2504, 1.4021, 0.9804, 0.49670000000000003, ...</td>\n","      <td>[2.243, 2.9361, 1.0553, 0.721, 0.6396000000000...</td>\n","      <td>[0.5163, 1.6823000000000001, 1.0426, 0.7902, 0...</td>\n","      <td>[0.9501000000000001, 1.7974999999999999, 1.499...</td>\n","      <td>[0.49438652400000005, 1.359932065, 1.182132720...</td>\n","      <td>[0.5494311452, 1.5888272524, 0.781946122600000...</td>\n","      <td>[2.2362072468, 3.0743534565, 1.0018054247, 0.6...</td>\n","      <td>[0.45601245760000003, 1.6323196888, 1.20958185...</td>\n","      <td>[0.7719741464000001, 1.9179110527, 1.328220725...</td>\n","      <td>107.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>9</td>\n","      <td>id_010ab0472</td>\n","      <td>GGAAAGCAUGGGACCACGAUUCACAUCGGUCUGCACGUAGGACAUU...</td>\n","      <td>.....(((...((((..(((....))))))))))(((((((((......</td>\n","      <td>EEEEESSSBBBSSSSBBSSSHHHHSSSSSSSSSSSSSSSSSSSIII...</td>\n","      <td>5.545</td>\n","      <td>1.0</td>\n","      <td>107</td>\n","      <td>68</td>\n","      <td>[0.1754, 0.1784, 0.1526, 0.1331, 0.13720000000...</td>\n","      <td>...</td>\n","      <td>[0.6237, 1.0674, 1.2511, 0.30560000000000004, ...</td>\n","      <td>[1.8982, 2.2653, 1.5584, 0.7352000000000001, 0...</td>\n","      <td>[0.23140000000000002, 1.1193, 1.103, 0.5249, 0...</td>\n","      <td>[1.0121, 2.0629, 1.3669, 0.9423, 0.88040000000...</td>\n","      <td>[0.3939593136, 0.7397066951, 0.9841383696, 0.5...</td>\n","      <td>[0.5187180638000001, 1.2671017647, 0.920283854...</td>\n","      <td>[2.1809523106, 2.4730124474, 1.2828187943, 0.5...</td>\n","      <td>[0.4119487107, 1.1664626598, 1.2020825148, 0.6...</td>\n","      <td>[0.640965879, 1.6035062075000002, 1.2896068096...</td>\n","      <td>107.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>10</td>\n","      <td>id_0172c2cb6</td>\n","      <td>GGAAAAUGCGAUCUAGGUAUAUAAGGAUGUUGUAGAAGAUCUUAUA...</td>\n","      <td>.......(((.(((((((((((..(((((((((((......)))))...</td>\n","      <td>EEEEEEESSSBSSSSSSSSSSSBBSSSSSSSSSSSHHHHHHSSSSS...</td>\n","      <td>5.934</td>\n","      <td>1.0</td>\n","      <td>107</td>\n","      <td>68</td>\n","      <td>[0.1612, 0.1985, 0.1557, 0.11270000000000001, ...</td>\n","      <td>...</td>\n","      <td>[1.0153, 2.6253, 0.8534, 0.3032, 1.0661, 1.126...</td>\n","      <td>[2.5968999999999998, 4.1737, 1.0042, 0.3202000...</td>\n","      <td>[0.5901000000000001, 3.3422, 1.3103, 0.2729000...</td>\n","      <td>[0.7395, 3.2518000000000002, 1.1306, 0.4777, 1...</td>\n","      <td>[0.6549244523000001, 1.8618059158, 0.995630085...</td>\n","      <td>[0.8233569264, 2.7822380066, 0.825156748300000...</td>\n","      <td>[2.7171478271, 4.2157297134, 1.1032375097, 0.3...</td>\n","      <td>[0.6204099655, 3.490240097, 1.379308939, 0.340...</td>\n","      <td>[0.9519925117, 3.3957703114, 1.2590910196, 0.4...</td>\n","      <td>107.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>11</td>\n","      <td>id_0197d5afb</td>\n","      <td>GGAAAGCGAUCACGAAAACCGAAACGAGAAACAUGAAACAAGUAAC...</td>\n","      <td>.....((((.(.(((...(((...((((..((.((...)).))..)...</td>\n","      <td>EEEEESSSSISISSSIIISSSIIISSSSIISSISSHHHSSISSIIS...</td>\n","      <td>9.540</td>\n","      <td>1.0</td>\n","      <td>107</td>\n","      <td>68</td>\n","      <td>[0.109, 0.13720000000000002, 0.128400000000000...</td>\n","      <td>...</td>\n","      <td>[0.889, 2.1651, 1.1683, 0.7428, 0.4701, 0.2363...</td>\n","      <td>[1.9673, 2.9951, 1.3573, 1.1557, 0.68780000000...</td>\n","      <td>[0.73, 2.045, 1.7421, 1.0795, 0.3972, 0.1489, ...</td>\n","      <td>[0.9172, 2.0825, 1.6199, 1.0091, 0.8051, 0.223...</td>\n","      <td>[0.7131134868, 1.8935495615, 1.5325232744, 0.9...</td>\n","      <td>[1.0514235497, 2.0816664696, 1.0307605267, 0.6...</td>\n","      <td>[2.1874666214, 2.9944462776, 1.4379746914, 0.9...</td>\n","      <td>[0.7964622378, 2.0651044846, 1.5697842836, 0.9...</td>\n","      <td>[0.8278126717000001, 2.2268886566, 1.552367806...</td>\n","      <td>107.0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>906</th>\n","      <td>2384</td>\n","      <td>id_fe1d9a133</td>\n","      <td>GGAAAGUGCUCAGAUAAGCUAAGCUCGAAUAGCAAUCGAAUAGAAU...</td>\n","      <td>.....((((.((.....((((.(((.....)))..((((......)...</td>\n","      <td>EEEEESSSSISSIIIIISSSSMSSSHHHHHSSSMMSSSSHHHHHHS...</td>\n","      <td>7.580</td>\n","      <td>1.0</td>\n","      <td>107</td>\n","      <td>68</td>\n","      <td>[0.12010000000000001, 0.1525, 0.1396, 0.1106, ...</td>\n","      <td>...</td>\n","      <td>[0.3305, 1.437, 0.8234, 1.0648, 0.6247, 0.9335...</td>\n","      <td>[2.1909, 2.9298, 0.9977, 0.5186000000000001, 0...</td>\n","      <td>[0.6749, 1.4787, 1.283, 0.8842000000000001, 0....</td>\n","      <td>[0.8941, 1.8928, 1.2547000000000001, 0.9153, 0...</td>\n","      <td>[0.5509190559, 1.429730773, 1.1915867329, 0.76...</td>\n","      <td>[0.5737138391000001, 1.5994940996, 0.763644099...</td>\n","      <td>[2.2023465633, 3.0511682034, 1.0011123419, 0.6...</td>\n","      <td>[0.4647729397, 1.5816473961000002, 1.147231221...</td>\n","      <td>[0.7838863730000001, 1.856931448, 1.267947793,...</td>\n","      <td>107.0</td>\n","    </tr>\n","    <tr>\n","      <th>907</th>\n","      <td>2386</td>\n","      <td>id_fe2edbdb0</td>\n","      <td>GGAAAGGAAGGUACGCACGUUACUUCCGACAAACUGGUAUCAGAGG...</td>\n","      <td>.........((((((((((((((((((..(...(((....))).)....</td>\n","      <td>EEEEEEEEESSSSSSSSSSSSSSSSSSIISIIISSSHHHHSSSISI...</td>\n","      <td>11.589</td>\n","      <td>0.0</td>\n","      <td>107</td>\n","      <td>68</td>\n","      <td>[0.0809, 0.09290000000000001, 0.0824, 0.0655, ...</td>\n","      <td>...</td>\n","      <td>[0.6967, 1.4562, 0.8852000000000001, 0.5627, 0...</td>\n","      <td>[2.1051, 3.5022, 1.2833, 0.9066000000000001, 0...</td>\n","      <td>[0.38520000000000004, 1.2137, 1.161, 0.8485, 0...</td>\n","      <td>[0.598, 1.28, 1.0233, 0.9363, 0.3564, 0.6823, ...</td>\n","      <td>[0.7332333326, 1.6247564554, 1.3998235464, 0.8...</td>\n","      <td>[0.5232779980000001, 1.6269822121000002, 0.898...</td>\n","      <td>[1.971732378, 3.4313290119, 1.5225758553, 0.83...</td>\n","      <td>[0.4386957884, 1.2857265472, 1.2891670465, 0.8...</td>\n","      <td>[0.6369811893, 1.4599643946, 1.2101275921, 0.9...</td>\n","      <td>107.0</td>\n","    </tr>\n","    <tr>\n","      <th>908</th>\n","      <td>2387</td>\n","      <td>id_fe7a3fdc6</td>\n","      <td>GGAAAGCCCGCGGCGCCGGGAGAGGAGGAAGACCAGGCAGCGCGGC...</td>\n","      <td>.....(((((((..(((((.............)).)))..)))))....</td>\n","      <td>EEEEESSSSSSSIISSSSSHHHHHHHHHHHHHSSBSSSIISSSSSB...</td>\n","      <td>5.029</td>\n","      <td>1.0</td>\n","      <td>107</td>\n","      <td>68</td>\n","      <td>[0.1505, 0.16620000000000001, 0.1487, 0.0896, ...</td>\n","      <td>...</td>\n","      <td>[0.6559, 1.3306, 1.2296, 0.8326, 0.403, 0.2002...</td>\n","      <td>[2.3598, 2.467, 1.0936, 0.5884, 0.5696, 0.2877...</td>\n","      <td>[0.32680000000000003, 1.6248, 1.431, 0.6498, 0...</td>\n","      <td>[0.6221, 1.4879, 1.1483, 0.752, 0.2908, 0.195,...</td>\n","      <td>[0.5441874862, 1.2684439421, 1.1897821426, 0.5...</td>\n","      <td>[0.6730461121, 1.5921000242, 1.1069828272, 0.5...</td>\n","      <td>[2.0878927708, 2.3091480732, 0.9754852653, 0.5...</td>\n","      <td>[0.5470023751, 1.7091696262, 1.574790120099999...</td>\n","      <td>[0.6363326907, 1.5836366415, 1.1049795151, 0.6...</td>\n","      <td>107.0</td>\n","    </tr>\n","    <tr>\n","      <th>909</th>\n","      <td>2398</td>\n","      <td>id_ffe06f3fe</td>\n","      <td>GGAAACGAUAGCAGAAGAGAUCGAUAUAGAGCAUAAGCUAAGAAUA...</td>\n","      <td>.....((((..(....)..))))......(((....)))..........</td>\n","      <td>EEEEESSSSIISHHHHSIISSSSXXXXXXSSSHHHHSSSXXXXXXX...</td>\n","      <td>5.553</td>\n","      <td>0.0</td>\n","      <td>107</td>\n","      <td>68</td>\n","      <td>[0.1431, 0.1847, 0.15960000000000002, 0.1466, ...</td>\n","      <td>...</td>\n","      <td>[0.4544, 2.4603, 0.8778, 0.6402, 0.28340000000...</td>\n","      <td>[2.7157999999999998, 3.1249000000000002, 1.137...</td>\n","      <td>[0.3262, 1.3932, 0.8832000000000001, 0.8144, 0...</td>\n","      <td>[0.5814, 1.5119, 1.1749, 1.2676, 0.22190000000...</td>\n","      <td>[0.5340527892, 1.4096640348, 1.2523895502, 1.2...</td>\n","      <td>[0.5563195944, 3.0136911869, 0.6894004941, 0.5...</td>\n","      <td>[2.9818921089, 3.1203522682, 1.2634347677, 0.9...</td>\n","      <td>[0.41576784850000004, 1.2947750091999999, 0.93...</td>\n","      <td>[0.6925363541, 1.4388481379, 1.254982113800000...</td>\n","      <td>107.0</td>\n","    </tr>\n","    <tr>\n","      <th>910</th>\n","      <td>2399</td>\n","      <td>id_fff546103</td>\n","      <td>GGAAAGCUAGGACGUGGGAGCGUAGCUCUCCACACGGGUACGCCAA...</td>\n","      <td>.....((((((((((((((((...)))).)))).((((((((((.....</td>\n","      <td>EEEEESSSSSSSSSSSSSSSSHHHSSSSBSSSSMSSSSSSSSSSHH...</td>\n","      <td>6.545</td>\n","      <td>1.0</td>\n","      <td>107</td>\n","      <td>68</td>\n","      <td>[0.1782, 0.2043, 0.1842, 0.13240000000000002, ...</td>\n","      <td>...</td>\n","      <td>[1.4842, 2.4813, 1.737, 1.2082, 0.959000000000...</td>\n","      <td>[2.3588, 2.2161, 1.2522, 0.7875000000000001, 0...</td>\n","      <td>[1.3281, 2.3854, 2.0464, 1.2384, 0.631, 0.1848...</td>\n","      <td>[0.7043, 1.4864, 1.3035, 1.2176, 0.82900000000...</td>\n","      <td>[1.1754118204, 1.6897300482, 1.900677084899999...</td>\n","      <td>[1.5074114799, 2.5505914688, 1.7496330738, 1.2...</td>\n","      <td>[2.1665196419, 1.9806636572, 1.266466021499999...</td>\n","      <td>[1.2031567097, 2.271261692, 2.0733299255, 1.39...</td>\n","      <td>[0.8833866119, 1.2434929609, 1.1088634729, 0.9...</td>\n","      <td>107.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>911 rows × 25 columns</p>\n","</div>"],"text/plain":["     index            id                                           sequence  \\\n","0        0  id_001f94081  GGAAAAGCUCUAAUAACAGGAGACUAGGACUACGUAUUUCUAGGUA...   \n","1        2  id_006f36f57  GGAAAGUGCUCAGAUAAGCUAAGCUCGAAUAGCAAUCGAAUAGAAU...   \n","2        9  id_010ab0472  GGAAAGCAUGGGACCACGAUUCACAUCGGUCUGCACGUAGGACAUU...   \n","3       10  id_0172c2cb6  GGAAAAUGCGAUCUAGGUAUAUAAGGAUGUUGUAGAAGAUCUUAUA...   \n","4       11  id_0197d5afb  GGAAAGCGAUCACGAAAACCGAAACGAGAAACAUGAAACAAGUAAC...   \n","..     ...           ...                                                ...   \n","906   2384  id_fe1d9a133  GGAAAGUGCUCAGAUAAGCUAAGCUCGAAUAGCAAUCGAAUAGAAU...   \n","907   2386  id_fe2edbdb0  GGAAAGGAAGGUACGCACGUUACUUCCGACAAACUGGUAUCAGAGG...   \n","908   2387  id_fe7a3fdc6  GGAAAGCCCGCGGCGCCGGGAGAGGAGGAAGACCAGGCAGCGCGGC...   \n","909   2398  id_ffe06f3fe  GGAAACGAUAGCAGAAGAGAUCGAUAUAGAGCAUAAGCUAAGAAUA...   \n","910   2399  id_fff546103  GGAAAGCUAGGACGUGGGAGCGUAGCUCUCCACACGGGUACGCCAA...   \n","\n","                                             structure  \\\n","0    .....((((((.......)))).)).((.....((..((((((......   \n","1    .....((((.((.....((((.(((.....)))..((((......)...   \n","2    .....(((...((((..(((....))))))))))(((((((((......   \n","3    .......(((.(((((((((((..(((((((((((......)))))...   \n","4    .....((((.(.(((...(((...((((..((.((...)).))..)...   \n","..                                                 ...   \n","906  .....((((.((.....((((.(((.....)))..((((......)...   \n","907  .........((((((((((((((((((..(...(((....))).)....   \n","908  .....(((((((..(((((.............)).)))..)))))....   \n","909  .....((((..(....)..))))......(((....)))..........   \n","910  .....((((((((((((((((...)))).)))).((((((((((.....   \n","\n","                                   predicted_loop_type  signal_to_noise  \\\n","0    EEEEESSSSSSHHHHHHHSSSSBSSXSSIIIIISSIISSSSSSHHH...            6.894   \n","1    EEEEESSSSISSIIIIISSSSMSSSHHHHHSSSMMSSSSHHHHHHS...            8.800   \n","2    EEEEESSSBBBSSSSBBSSSHHHHSSSSSSSSSSSSSSSSSSSIII...            5.545   \n","3    EEEEEEESSSBSSSSSSSSSSSBBSSSSSSSSSSSHHHHHHSSSSS...            5.934   \n","4    EEEEESSSSISISSSIIISSSIIISSSSIISSISSHHHSSISSIIS...            9.540   \n","..                                                 ...              ...   \n","906  EEEEESSSSISSIIIIISSSSMSSSHHHHHSSSMMSSSSHHHHHHS...            7.580   \n","907  EEEEEEEEESSSSSSSSSSSSSSSSSSIISIIISSSHHHHSSSISI...           11.589   \n","908  EEEEESSSSSSSIISSSSSHHHHHHHHHHHHHSSBSSSIISSSSSB...            5.029   \n","909  EEEEESSSSIISHHHHSIISSSSXXXXXXSSSHHHHSSSXXXXXXX...            5.553   \n","910  EEEEESSSSSSSSSSSSSSSSHHHSSSSBSSSSMSSSSSSSSSSHH...            6.545   \n","\n","     SN_filter  seq_length  seq_scored  \\\n","0          1.0         107          68   \n","1          1.0         107          68   \n","2          1.0         107          68   \n","3          1.0         107          68   \n","4          1.0         107          68   \n","..         ...         ...         ...   \n","906        1.0         107          68   \n","907        0.0         107          68   \n","908        1.0         107          68   \n","909        0.0         107          68   \n","910        1.0         107          68   \n","\n","                                      reactivity_error  ...  \\\n","0    [0.1359, 0.20700000000000002, 0.1633, 0.1452, ...  ...   \n","1    [0.0931, 0.13290000000000002, 0.11280000000000...  ...   \n","2    [0.1754, 0.1784, 0.1526, 0.1331, 0.13720000000...  ...   \n","3    [0.1612, 0.1985, 0.1557, 0.11270000000000001, ...  ...   \n","4    [0.109, 0.13720000000000002, 0.128400000000000...  ...   \n","..                                                 ...  ...   \n","906  [0.12010000000000001, 0.1525, 0.1396, 0.1106, ...  ...   \n","907  [0.0809, 0.09290000000000001, 0.0824, 0.0655, ...  ...   \n","908  [0.1505, 0.16620000000000001, 0.1487, 0.0896, ...  ...   \n","909  [0.1431, 0.1847, 0.15960000000000002, 0.1466, ...  ...   \n","910  [0.1782, 0.2043, 0.1842, 0.13240000000000002, ...  ...   \n","\n","                                           deg_Mg_pH10  \\\n","0    [0.7556, 2.983, 0.2526, 1.3789, 0.637600000000...   \n","1    [0.2504, 1.4021, 0.9804, 0.49670000000000003, ...   \n","2    [0.6237, 1.0674, 1.2511, 0.30560000000000004, ...   \n","3    [1.0153, 2.6253, 0.8534, 0.3032, 1.0661, 1.126...   \n","4    [0.889, 2.1651, 1.1683, 0.7428, 0.4701, 0.2363...   \n","..                                                 ...   \n","906  [0.3305, 1.437, 0.8234, 1.0648, 0.6247, 0.9335...   \n","907  [0.6967, 1.4562, 0.8852000000000001, 0.5627, 0...   \n","908  [0.6559, 1.3306, 1.2296, 0.8326, 0.403, 0.2002...   \n","909  [0.4544, 2.4603, 0.8778, 0.6402, 0.28340000000...   \n","910  [1.4842, 2.4813, 1.737, 1.2082, 0.959000000000...   \n","\n","                                              deg_pH10  \\\n","0    [2.3375, 3.5060000000000002, 0.3008, 1.0108, 0...   \n","1    [2.243, 2.9361, 1.0553, 0.721, 0.6396000000000...   \n","2    [1.8982, 2.2653, 1.5584, 0.7352000000000001, 0...   \n","3    [2.5968999999999998, 4.1737, 1.0042, 0.3202000...   \n","4    [1.9673, 2.9951, 1.3573, 1.1557, 0.68780000000...   \n","..                                                 ...   \n","906  [2.1909, 2.9298, 0.9977, 0.5186000000000001, 0...   \n","907  [2.1051, 3.5022, 1.2833, 0.9066000000000001, 0...   \n","908  [2.3598, 2.467, 1.0936, 0.5884, 0.5696, 0.2877...   \n","909  [2.7157999999999998, 3.1249000000000002, 1.137...   \n","910  [2.3588, 2.2161, 1.2522, 0.7875000000000001, 0...   \n","\n","                                            deg_Mg_50C  \\\n","0    [0.35810000000000003, 2.9683, 0.2589, 1.4552, ...   \n","1    [0.5163, 1.6823000000000001, 1.0426, 0.7902, 0...   \n","2    [0.23140000000000002, 1.1193, 1.103, 0.5249, 0...   \n","3    [0.5901000000000001, 3.3422, 1.3103, 0.2729000...   \n","4    [0.73, 2.045, 1.7421, 1.0795, 0.3972, 0.1489, ...   \n","..                                                 ...   \n","906  [0.6749, 1.4787, 1.283, 0.8842000000000001, 0....   \n","907  [0.38520000000000004, 1.2137, 1.161, 0.8485, 0...   \n","908  [0.32680000000000003, 1.6248, 1.431, 0.6498, 0...   \n","909  [0.3262, 1.3932, 0.8832000000000001, 0.8144, 0...   \n","910  [1.3281, 2.3854, 2.0464, 1.2384, 0.631, 0.1848...   \n","\n","                                               deg_50C  \\\n","0    [0.6382, 3.4773, 0.9988, 1.3228, 0.78770000000...   \n","1    [0.9501000000000001, 1.7974999999999999, 1.499...   \n","2    [1.0121, 2.0629, 1.3669, 0.9423, 0.88040000000...   \n","3    [0.7395, 3.2518000000000002, 1.1306, 0.4777, 1...   \n","4    [0.9172, 2.0825, 1.6199, 1.0091, 0.8051, 0.223...   \n","..                                                 ...   \n","906  [0.8941, 1.8928, 1.2547000000000001, 0.9153, 0...   \n","907  [0.598, 1.28, 1.0233, 0.9363, 0.3564, 0.6823, ...   \n","908  [0.6221, 1.4879, 1.1483, 0.752, 0.2908, 0.195,...   \n","909  [0.5814, 1.5119, 1.1749, 1.2676, 0.22190000000...   \n","910  [0.7043, 1.4864, 1.3035, 1.2176, 0.82900000000...   \n","\n","                                     pseudo_reactivity  \\\n","0    [0.34715089200000004, 1.5796933174, 1.12351059...   \n","1    [0.49438652400000005, 1.359932065, 1.182132720...   \n","2    [0.3939593136, 0.7397066951, 0.9841383696, 0.5...   \n","3    [0.6549244523000001, 1.8618059158, 0.995630085...   \n","4    [0.7131134868, 1.8935495615, 1.5325232744, 0.9...   \n","..                                                 ...   \n","906  [0.5509190559, 1.429730773, 1.1915867329, 0.76...   \n","907  [0.7332333326, 1.6247564554, 1.3998235464, 0.8...   \n","908  [0.5441874862, 1.2684439421, 1.1897821426, 0.5...   \n","909  [0.5340527892, 1.4096640348, 1.2523895502, 1.2...   \n","910  [1.1754118204, 1.6897300482, 1.900677084899999...   \n","\n","                                    pseudo_deg_Mg_pH10  \\\n","0    [0.6049603224, 2.9363353252, 0.2550430596, 1.2...   \n","1    [0.5494311452, 1.5888272524, 0.781946122600000...   \n","2    [0.5187180638000001, 1.2671017647, 0.920283854...   \n","3    [0.8233569264, 2.7822380066, 0.825156748300000...   \n","4    [1.0514235497, 2.0816664696, 1.0307605267, 0.6...   \n","..                                                 ...   \n","906  [0.5737138391000001, 1.5994940996, 0.763644099...   \n","907  [0.5232779980000001, 1.6269822121000002, 0.898...   \n","908  [0.6730461121, 1.5921000242, 1.1069828272, 0.5...   \n","909  [0.5563195944, 3.0136911869, 0.6894004941, 0.5...   \n","910  [1.5074114799, 2.5505914688, 1.7496330738, 1.2...   \n","\n","                                       pseudo_deg_pH10  \\\n","0    [2.6121025085, 3.5633585453, 0.3173390031, 0.9...   \n","1    [2.2362072468, 3.0743534565, 1.0018054247, 0.6...   \n","2    [2.1809523106, 2.4730124474, 1.2828187943, 0.5...   \n","3    [2.7171478271, 4.2157297134, 1.1032375097, 0.3...   \n","4    [2.1874666214, 2.9944462776, 1.4379746914, 0.9...   \n","..                                                 ...   \n","906  [2.2023465633, 3.0511682034, 1.0011123419, 0.6...   \n","907  [1.971732378, 3.4313290119, 1.5225758553, 0.83...   \n","908  [2.0878927708, 2.3091480732, 0.9754852653, 0.5...   \n","909  [2.9818921089, 3.1203522682, 1.2634347677, 0.9...   \n","910  [2.1665196419, 1.9806636572, 1.266466021499999...   \n","\n","                                     pseudo_deg_Mg_50C  \\\n","0    [0.4698945284, 3.3145470619, 0.2526535988, 1.6...   \n","1    [0.45601245760000003, 1.6323196888, 1.20958185...   \n","2    [0.4119487107, 1.1664626598, 1.2020825148, 0.6...   \n","3    [0.6204099655, 3.490240097, 1.379308939, 0.340...   \n","4    [0.7964622378, 2.0651044846, 1.5697842836, 0.9...   \n","..                                                 ...   \n","906  [0.4647729397, 1.5816473961000002, 1.147231221...   \n","907  [0.4386957884, 1.2857265472, 1.2891670465, 0.8...   \n","908  [0.5470023751, 1.7091696262, 1.574790120099999...   \n","909  [0.41576784850000004, 1.2947750091999999, 0.93...   \n","910  [1.2031567097, 2.271261692, 2.0733299255, 1.39...   \n","\n","                                        pseudo_deg_50C length  \n","0    [0.7628977299, 3.3258330822, 0.772382319000000...  107.0  \n","1    [0.7719741464000001, 1.9179110527, 1.328220725...  107.0  \n","2    [0.640965879, 1.6035062075000002, 1.2896068096...  107.0  \n","3    [0.9519925117, 3.3957703114, 1.2590910196, 0.4...  107.0  \n","4    [0.8278126717000001, 2.2268886566, 1.552367806...  107.0  \n","..                                                 ...    ...  \n","906  [0.7838863730000001, 1.856931448, 1.267947793,...  107.0  \n","907  [0.6369811893, 1.4599643946, 1.2101275921, 0.9...  107.0  \n","908  [0.6363326907, 1.5836366415, 1.1049795151, 0.6...  107.0  \n","909  [0.6925363541, 1.4388481379, 1.254982113800000...  107.0  \n","910  [0.8833866119, 1.2434929609, 1.1088634729, 0.9...  107.0  \n","\n","[911 rows x 25 columns]"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["highSN=train_step3.loc[train_step3['signal_to_noise']>5].reset_index(drop=True)\n","highSN"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["class RNA_Dataset(Dataset):\n","    def __init__(self,data, length=68):\n","        self.data=data\n","        self.length=length\n","        self.tokens={nt:i for i,nt in enumerate('ACGU')}\n","        self.label_names=['reactivity', 'deg_Mg_pH10', 'deg_pH10', 'deg_Mg_50C', 'deg_50C']\n","               \n","    def __len__(self):\n","        return len(self.data)\n","    \n","    def __getitem__(self, idx):\n","        sequence=[self.tokens[nt] for nt in (self.data.loc[idx,'sequence'])]\n","        sequence=np.array(sequence)\n","        sequence=torch.tensor(sequence)\n","        seq_len=len(sequence)\n","        if len(sequence)<self.length:\n","            sequence=torch.cat([sequence,torch.ones(self.length-len(sequence)).long()*4])\n","        labels=np.stack([self.data.loc[idx,l] for l in self.label_names],-1)\n","        labels=torch.tensor(labels)\n","        if len(labels)>self.length:\n","            labels=labels[:self.length]\n","        else:\n","            labels=torch.cat([labels,torch.zeros(self.length-len(labels),5)])\n","        return {'sequence':sequence,\n","                \"length\": seq_len,\n","                'labels':labels}\n","train_loader3=DataLoader(RNA_Dataset(train_step3,130),batch_size=32,shuffle=True)\n","highSN_loader=DataLoader(RNA_Dataset(highSN),batch_size=32,shuffle=True)\n","val_loader = DataLoader(RNA_Dataset(val_split),batch_size=32,shuffle=False)"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Ranger optimizer loaded. \n","Gradient Centralization usage = True\n","GC applied to both conv and fc layers\n"]},{"name":"stderr","output_type":"stream","text":["  0%|          | 0/5824 [00:00<?, ?it/s]"]},{"name":"stderr","output_type":"stream","text":["/Users/lihongmin/mambaforge/envs/torch/lib/python3.9/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n","  warnings.warn(\n","/Users/lihongmin/Research/ideas/RibonanzaNet/Ranger-Deep-Learning-Optimizer/ranger/ranger.py:138: UserWarning: This overload of addcmul_ is deprecated:\n","\taddcmul_(Number value, Tensor tensor1, Tensor tensor2)\n","Consider using one of the following signatures instead:\n","\taddcmul_(Tensor tensor1, Tensor tensor2, *, Number value) (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/python_arg_parser.cpp:1630.)\n","  exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n","Epoch 1 Loss: 0.05741212020317713:   2%|▏         | 108/5824 [00:43<38:36,  2.47it/s] \n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[12], line 55\u001b[0m\n\u001b[1;32m     52\u001b[0m         loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     54\u001b[0m         torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), \u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m---> 55\u001b[0m         \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m#         if (epoch+1)>cos_epoch:\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m#             schedule.step()\u001b[39;00m\n\u001b[1;32m     60\u001b[0m         \u001b[38;5;66;03m#schedule.step()\u001b[39;00m\n","File \u001b[0;32m~/mambaforge/envs/torch/lib/python3.9/site-packages/torch/optim/optimizer.py:385\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    381\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    382\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    383\u001b[0m             )\n\u001b[0;32m--> 385\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    388\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n","File \u001b[0;32m~/Research/ideas/RibonanzaNet/Ranger-Deep-Learning-Optimizer/ranger/ranger.py:167\u001b[0m, in \u001b[0;36mRanger.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m N_sma \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mN_sma_threshhold:\n\u001b[1;32m    166\u001b[0m     denom \u001b[38;5;241m=\u001b[39m exp_avg_sq\u001b[38;5;241m.\u001b[39msqrt()\u001b[38;5;241m.\u001b[39madd_(group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meps\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m--> 167\u001b[0m     \u001b[43mp_data_fp32\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maddcdiv_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mstep_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\n\u001b[1;32m    168\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexp_avg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdenom\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    170\u001b[0m     p_data_fp32\u001b[38;5;241m.\u001b[39madd_(\u001b[38;5;241m-\u001b[39mstep_size \u001b[38;5;241m*\u001b[39m group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m], exp_avg)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["from ranger import Ranger\n","from tqdm import tqdm\n","#loss function\n","def MCRMAE(y_pred, y_true):\n","    # 计算每列的MAE\n","    colwise_mae = torch.mean(torch.abs(y_true - y_pred), dim=0)\n","    # 计算列MAE的均值\n","    MCRMAE = torch.mean(colwise_mae)\n","    return MCRMAE\n","\n","epochs=20\n","cos_epoch=15\n","\n","best_loss=np.inf\n","optimizer = Ranger(model.parameters(), lr=0.001)\n","\n","\n","criterion=MCRMAE\n","lr = 0.001\n","# schedule=torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=(epochs-cos_epoch)*len(train_loader))\n","\n","\n","for epoch in range(epochs):\n","    model.train()\n","    tbar=tqdm(train_loader3)\n","    total_loss=0\n","    oom=0\n","    for idx, batch in enumerate(tbar):\n","        sequence=batch['sequence'].to(device)\n","        labels=batch['labels'].float().to(device)\n","        seq_length=batch['length'].to(device)\n","        output=model(sequence)\n","        \n","        sliced_outputs = []\n","        slice_labels = []       \n","\n","        for i in range(output.size(0)):  # Loop through each batch\n","            # Slice each batch up to its corresponding sequence length\n","            sliced_output = output[i, :seq_length[i], :]\n","            sliced_label = labels[i, :seq_length[i], :]\n","            # Append the sliced output to the list\n","            sliced_outputs.append(sliced_output)\n","            slice_labels.append(sliced_label)\n","\n","        # Concatenate all sliced outputs along the first dimension\n","        final_output = torch.cat(sliced_outputs, dim=0)\n","        final_labels = torch.cat(slice_labels, dim=0)\n","        \n","        loss=criterion(final_output,final_labels)\n","        loss=loss.mean()\n","\n","        loss.backward()\n","\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 10)\n","        optimizer.step()\n","        optimizer.zero_grad()\n","\n","#         if (epoch+1)>cos_epoch:\n","#             schedule.step()\n","        #schedule.step()\n","        total_loss+=loss.item()\n","\n","        tbar.set_description(f\"Epoch {epoch + 1} Loss: {total_loss/(idx+1)}\")\n","        #break\n","\n","    tbar=tqdm(val_loader)\n","    model.eval()\n","    val_preds=[]\n","    val_loss=0\n","    for idx, batch in enumerate(tbar):\n","        sequence=batch['sequence'].to(device)\n","        labels=batch['labels'].float().to(device)\n","\n","        with torch.no_grad():\n","            output=model(sequence)\n","            \n","            loss=criterion(output[:,:68],labels)\n","            loss=loss.mean()\n","        val_loss+=loss.item()\n","        val_preds.append([labels.cpu().numpy(),output.cpu().numpy()])\n","    val_loss=val_loss/len(tbar)\n","    print(f\"val loss: {val_loss}\")\n","    if val_loss<best_loss:\n","        best_loss=val_loss\n","        best_preds=val_preds\n","        torch.save(model.state_dict(),'RibonanzaNet-Deg_30.pt')\n","\n","    # 1.053595052265986 train loss after epoch 0"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from ranger import Ranger\n","from tqdm import tqdm\n","#loss function\n","def MCRMAE(y_pred, y_true):\n","    # 计算每列的MAE\n","    colwise_mae = torch.mean(torch.abs(y_true - y_pred), dim=0)\n","    # 计算列MAE的均值\n","    MCRMAE = torch.mean(colwise_mae)\n","    return MCRMAE\n","\n","epochs=10\n","cos_epoch=7\n","\n","best_loss=np.inf\n","optimizer = Ranger(model.parameters(), weight_decay=0.001, lr=0.001)\n","\n","\n","criterion=MCRMAE\n","lr = 0.001\n","schedule=torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=(epochs-cos_epoch)*len(highSN_loader))\n","\n","\n","for epoch in range(epochs):\n","    model.train()\n","    tbar=tqdm(highSN_loader)\n","    total_loss=0\n","    oom=0\n","    for idx, batch in enumerate(tbar):\n","        sequence=batch['sequence'].to(device)\n","        labels=batch['labels'].float().to(device)\n","\n","        output=model(sequence)\n","\n","        loss=criterion(output[:,:68],labels)\n","        loss=loss.mean()\n","\n","        loss.backward()\n","\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 10)\n","        optimizer.step()\n","        optimizer.zero_grad()\n","\n","        if (epoch+1)>cos_epoch:\n","            schedule.step()\n","        total_loss+=loss.item()\n","\n","        tbar.set_description(f\"Epoch {epoch + 1} Loss: {total_loss/(idx+1)}\")\n","        #break\n","\n","    tbar=tqdm(val_loader)\n","    model.eval()\n","    val_preds=[]\n","    val_loss=0\n","    for idx, batch in enumerate(tbar):\n","        sequence=batch['sequence'].to(device)\n","        labels=batch['labels'].float().to(device)\n","\n","        with torch.no_grad():\n","            output=model(sequence)\n","            \n","            loss=criterion(output[:,:68],labels)\n","            loss=loss.mean()\n","        val_loss+=loss.item()\n","        val_preds.append([labels.cpu().numpy(),output.cpu().numpy()])\n","    val_loss=val_loss/len(tbar)\n","    print(f\"val loss: {val_loss}\")\n","    if val_loss<best_loss:\n","        best_loss=val_loss\n","        best_preds=val_preds\n","        torch.save(model.state_dict(),'RibonanzaNet-Deg_31.pt')\n","\n","    # 1.053595052265986 train loss after epoch 0"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"databundleVersionId":1600624,"sourceId":22111,"sourceType":"competition"},{"datasetId":4299404,"sourceId":7395067,"sourceType":"datasetVersion"},{"datasetId":4299272,"sourceId":7639698,"sourceType":"datasetVersion"},{"datasetId":4459124,"sourceId":8318191,"sourceType":"datasetVersion"}],"dockerImageVersionId":30636,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.18"}},"nbformat":4,"nbformat_minor":4}
